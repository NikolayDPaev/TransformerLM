{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, codecs\n",
    "import random\n",
    "\n",
    "from TransformerLanguageModel import CustomTokenizer, TransformerLanguageModel, Trainer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '<S>'\n",
    "end_token = '</S>'\n",
    "pad_token = '<PAD>'\n",
    "vocab_size = 30000\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dataset.json', 'r', encoding=\"utf-8\") as f:\n",
    "    examples = json.load(f)\n",
    "\n",
    "split = int(0.05*len(examples))\n",
    "dev = examples[:split]\n",
    "train = examples[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CustomTokenizer(pad_token, start_token, end_token, vocab_size=vocab_size)\n",
    "tokenizer.train(train)\n",
    "tokenizer.save('tokenizer.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the tokenizer is already trained. Load it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.load('tokenizer.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = TransformerLanguageModel('lm', n_head=6, d_model=256, d_ff=4*256, layer_count=5, embed_dropout=0.3, cell_dropout=0.2, tokenizer=tokenizer).to(device)\n",
    "\n",
    "trainer = Trainer(vocab_size, 16, 10)\n",
    "trainer.train(lm, train, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.load('lm')\n",
    "trainer = Trainer(vocab_size, 16, 10)\n",
    "trainer.train(lm, train, dev, extra_train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "With nucleus sampling with inference parameter 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.generate_sentence(word_tokenize('Hello'), True, 'nuc', inference_parameter=0.9, limit=100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
